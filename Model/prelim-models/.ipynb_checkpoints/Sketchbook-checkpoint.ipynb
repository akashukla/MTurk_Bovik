{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# LIB IMPORTS\n",
    "#\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# fastai\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.imports import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation and Split\n",
    "Using functions in external scripts, prepare the data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-62-79e5ad25038b>\", line 18, in <module>\n",
      "    im_dict, data = make_predata(csv_files,column_headers)\n",
      "  File \"/Users/shwetha/UT/SD/MTurk_Bovik/Model/prelim-models/dataload.py\", line 28, in make_predata\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 709, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "OSError: Initializing from file failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Initializing from file failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#\n",
    "# GENERATE DATA\n",
    "#\n",
    "# Note this part may take some time\n",
    "from dataload import *\n",
    "from denoise import *\n",
    "from normalize import *\n",
    "\n",
    "csv_files = ['batch-data/batch1_results.csv',\n",
    "             'batch-data/batch2_results.csv',\n",
    "             'batch-data/batch3_results.csv',\n",
    "             'batch-data/batch4_results.csv',\n",
    "             'batch-data/batch5_results.csv',\n",
    "             'batch-data/batch6_results.csv']\n",
    "\n",
    "column_headers = ['AssignmentStatus','Answer.set_number','WorkerId','Answer.slider_values','Answer.slider_values2']\n",
    "\n",
    "im_dict, data = make_predata(csv_files,column_headers)\n",
    "\n",
    "# Denoise and get cleaned data\n",
    "percentile = 90\n",
    "cleaned_data = outlier_denoising(im_dict, data, percentile)\n",
    "\n",
    "# X contains the image names\n",
    "Images, X, y1, y2 = format_data(cleaned_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train set\n",
    "test_size = 0.2\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, \n",
    "                                                      y1, \n",
    "                                                      test_size=test_size, \n",
    "                                                      random_state=123)\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, \n",
    "                                                      y2, \n",
    "                                                      test_size=test_size, \n",
    "                                                      random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Beyond this point we are only trying slider 1\n",
    "\n",
    "#\n",
    "# Set up data format for regression based tl\n",
    "#\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('../data/8k_data/' + ID)\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "training_set = Dataset(X_train, y1_train)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(X_test, y1_test)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-60-73ea8b0ffa49>\", line 1, in <module>\n",
      "    model = models.resnet18(pretrained=True)\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\", line 231, in resnet18\n",
      "    **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\", line 217, in _resnet\n",
      "    progress=progress)\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/torch/hub.py\", line 499, in load_state_dict_from_url\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/torch/serialization.py\", line 419, in load\n",
      "OSError: [Errno 24] Too many open files: '/Users/shwetha/.cache/torch/checkpoints/resnet18-5c106cde.pth'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "  File \"/usr/local/anaconda3/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: '/Users/shwetha/.cache/torch/checkpoints/resnet18-5c106cde.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goats\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print('goats')\n",
    "    # Training\n",
    "    #for local_batch, local_labels in training_generator:\n",
    "        #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        \n",
    "    # Validation\n",
    "    #with torch.set_grad_enabled(False):\n",
    "        #for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
